{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f1feb07-9990-47a0-bc7e-202dc9dfbb68",
   "metadata": {},
   "source": [
    "# Testing EBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "7f46d981-9cba-4fb7-9e21-ab57fd6ef555",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy\n",
    "import openai\n",
    "import os\n",
    "import json\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from os.path import abspath\n",
    "from pathlib import Path\n",
    "from wasabi import Printer\n",
    "from tqdm import tqdm\n",
    "import spacy\n",
    "from dotenv import load_dotenv\n",
    "from tenacity import (\n",
    "    retry,\n",
    "    stop_after_attempt,\n",
    "    wait_random_exponential,\n",
    ")  # for exponential backoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f41f2bf-d29e-482a-8076-c2d60eb9ff0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = Printer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e82a0aa-c280-47d3-be75-09990cb66d2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "load_dotenv() # load enviroment variables\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef748e50-c73a-4443-9f9a-1334264a4d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ home directory: /Users/lars/Documents/GitHub/ebc_test\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "home_dir = Path(abspath(''))\n",
    "msg.info(f'home directory: {home_dir}')\n",
    "\n",
    "aop_wiki_abstracts_path = home_dir.joinpath('article_data/aop_wiki_abstracts.jsonl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1a5b75-d58d-4b57-90fb-e6f2776055d0",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37297fb5-3024-41d8-8370-f76c2d1a26cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aop_wiki_abstracts = []\n",
    "with aop_wiki_abstracts_path.open('r') as file:\n",
    "    for line in file:\n",
    "        aop_wiki_abstracts.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e669df-a6bf-4901-b889-fc098c66c5a6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Get shortest dependecy path between Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fdc273-7a79-4967-9035-e486f1314b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ents_with_gpt(doc, model, prompt_path):\n",
    "    pass\n",
    "\n",
    "    @retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(6))\n",
    "    def chatCompletion_with_backoff(**kwargs):\n",
    "        return openai.ChatCompletion.create(**kwargs)\n",
    "    \n",
    "    def read_response():\n",
    "        pass\n",
    "    \n",
    "    # loading prompt file\n",
    "    with open(prompt_path, 'r') as file:\n",
    "        prompt = file.read()\n",
    "        prompt = prompt.split('\\n')\n",
    "        \n",
    "    # Insert sentences into new prompt\n",
    "    for indx, sent in enumerate(doc.sents):\n",
    "    prompt.append(f'sentence {indx}:\\n'+'\"\"\"\\n'+f'{sent.text}\\n'+'\"\"\"')\n",
    "    \n",
    "    # convert prompt back to string\n",
    "    prompt = '\\n'.join(prompt)\n",
    "    \n",
    "    # query gpt\n",
    "    message=[\n",
    "            {'role':'system','content':system_message},\n",
    "            {'role':'user','content':prompt.format(text=abstract)}\n",
    "        ]\n",
    "    \n",
    "    # Get response\n",
    "    response = chatCompletion_with_backoff(\n",
    "        model=engine,\n",
    "        messages=message,\n",
    "        temperature=temp,\n",
    "        n=n\n",
    "    )\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "627a0c7d-98d9-4b68-ba60-8d9cd979d68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shortest_dependency_path(ent1, ent2):\n",
    "    \n",
    "    def go_up_tree(token):\n",
    "        path=[token.text, token.dep_]\n",
    "        if token == token.head:\n",
    "            # print(0, token, token.head)\n",
    "            return [token.text]\n",
    "        else:\n",
    "            # print(1, path, token.head)\n",
    "            return path+go_up_tree(token.head)\n",
    "        \n",
    "    path1 = go_up_tree(ent1.root)\n",
    "    path2 = go_up_tree(ent2.root)\n",
    "    \n",
    "    return path1 + path2[:-1][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "8179d2c4-8eb4-48a1-b62f-86e9a0d4e67a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4945/4945 [04:37<00:00, 17.80it/s]\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_tox')\n",
    "\n",
    "docs = nlp.pipe([doc['abstract'] for doc in aop_wiki_abstracts if type(doc['abstract'])==str])\n",
    "pmids = [doc['pmid'] for doc in aop_wiki_abstracts if type(doc['abstract'])==str]\n",
    "ent_labels_of_interest = ('PHENOTYPE', 'COMPOUND')\n",
    "\n",
    "data_dict = {\n",
    "    'entity A':[],\n",
    "    'entity B':[],\n",
    "    'label A':[],\n",
    "    'label B':[],\n",
    "    'shortest dep path':[],\n",
    "    'sentence':[],\n",
    "    'sentence id':[],\n",
    "    'pmid':[],\n",
    "}\n",
    "\n",
    "sentence_id = 0\n",
    "for doc, pmid in tqdm(zip(docs,pmids), total=len(pmids)):\n",
    "    for sent in doc.sents:\n",
    "        \n",
    "        # Is there a molecule and a phenotype in the sentence\n",
    "        if not set(ent_labels_of_interest).issubset(set([ent.label_ for ent in sent.ents])):\n",
    "            continue\n",
    "\n",
    "        # get the shortest dependency path of all combinations of molecule and phenotype\n",
    "        ents_of_interest = [ent for ent in sent.ents if ent.label_ in ent_labels_of_interest]\n",
    "        mirrors = []\n",
    "        for ent1, ent2 in itertools.product(ents_of_interest, ents_of_interest):\n",
    "            \n",
    "            ### Skips\n",
    "            if ent1 == ent2: # skip if ent1 is the same as ent2\n",
    "                continue\n",
    "                \n",
    "            if ent1.label == ent2.label: #skip if labels are the same\n",
    "                continue\n",
    "                \n",
    "            if (ent1, ent2) in mirrors: #SKIP mirrors (ent1+ent2 vs ent2+ent1)\n",
    "                continue\n",
    "            \n",
    "            # Store mirrors\n",
    "            mirrors.append((ent2, ent1))\n",
    "            \n",
    "            # get dependency path\n",
    "            shortest_dep_path = get_shortest_dependency_path(ent1, ent2) # Get shortest dependecy path\n",
    "            ent1_root = shortest_dep_path.pop(0)\n",
    "            ent2_root = shortest_dep_path.pop(-1)\n",
    "            \n",
    "            ### Save data \n",
    "            data_dict['entity A'].append(ent1.text)\n",
    "            data_dict['entity B'].append(ent2.text)\n",
    "            data_dict['label A'].append(ent1.label_)\n",
    "            data_dict['label B'].append(ent2.label_)\n",
    "            data_dict['shortest dep path'].append(str(shortest_dep_path))\n",
    "            data_dict['sentence'].append(sent.text)\n",
    "            data_dict['sentence id'].append(sentence_id)\n",
    "            data_dict['pmid'].append(pmid)\n",
    "            data_dict['entity A root'].append(ent1_root)\n",
    "            data_dict['entity B root'].append(ent2_root)\n",
    "        \n",
    "        # Increment sentence id\n",
    "        sentence_id = sentence_id + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb9890e-e5ae-42e5-beb1-db01269686d7",
   "metadata": {},
   "source": [
    "##### Small analysis of dependency paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "fc268ced-979e-4fcb-a148-ee973975f6f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentences in which at least one molecule name and at least one phenotype are present 5118\n",
      "total number of unique molecule-phenotype-sentence combinations 11054\n",
      "total number of unique dependency paths (not accounting for mirrors): 9542\n"
     ]
    }
   ],
   "source": [
    "print('sentences in which at least one molecule name and at least one phenotype are present', len(set(data_dict['sentence id'])))\n",
    "print('total number of unique molecule-phenotype-sentence combinations', len(set([(entityA, entityB, sentence_id) for entityA, entityB, sentence_id in zip(data_dict['entity A'], data_dict['entity B'], data_dict['sentence id'])])))\n",
    "print('total number of unique dependency paths (not accounting for mirrors):', len(set(data_dict['shortest dep path'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "96231d96-e1d0-4262-b339-4872bdb9911c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity A</th>\n",
       "      <th>entity B</th>\n",
       "      <th>label A</th>\n",
       "      <th>label B</th>\n",
       "      <th>shortest dep path</th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentence id</th>\n",
       "      <th>pmid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dioxane</td>\n",
       "      <td>mortality</td>\n",
       "      <td>COMPOUND</td>\n",
       "      <td>PHENOTYPE</td>\n",
       "      <td>['nmod', 'effect', 'nmod', 'interest', 'nmod',...</td>\n",
       "      <td>As a result of recent interest in the carcinog...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vildagliptin</td>\n",
       "      <td>performance</td>\n",
       "      <td>COMPOUND</td>\n",
       "      <td>PHENOTYPE</td>\n",
       "      <td>['nsubj', 'improved', 'dobj']</td>\n",
       "      <td>Vildagliptin markedly improved the motor perfo...</td>\n",
       "      <td>1</td>\n",
       "      <td>25752913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vildagliptin</td>\n",
       "      <td>reduction</td>\n",
       "      <td>COMPOUND</td>\n",
       "      <td>PHENOTYPE</td>\n",
       "      <td>['nsubj', 'improved', 'dep', 'effects', 'acl:r...</td>\n",
       "      <td>Vildagliptin markedly improved the motor perfo...</td>\n",
       "      <td>1</td>\n",
       "      <td>25752913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>product</td>\n",
       "      <td>vildagliptin</td>\n",
       "      <td>PHENOTYPE</td>\n",
       "      <td>COMPOUND</td>\n",
       "      <td>['nmod', 'Normalization', 'nsubj', 'finding', ...</td>\n",
       "      <td>Normalization of receptor for advanced glycate...</td>\n",
       "      <td>2</td>\n",
       "      <td>25752913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vildagliptin</td>\n",
       "      <td>molecule-1</td>\n",
       "      <td>COMPOUND</td>\n",
       "      <td>PHENOTYPE</td>\n",
       "      <td>['nmod', 'effects', 'dobj', 'justifies', 'acl:...</td>\n",
       "      <td>Normalization of receptor for advanced glycate...</td>\n",
       "      <td>2</td>\n",
       "      <td>25752913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       entity A      entity B    label A    label B  \\\n",
       "0       dioxane     mortality   COMPOUND  PHENOTYPE   \n",
       "1  Vildagliptin   performance   COMPOUND  PHENOTYPE   \n",
       "2  Vildagliptin     reduction   COMPOUND  PHENOTYPE   \n",
       "3       product  vildagliptin  PHENOTYPE   COMPOUND   \n",
       "4  vildagliptin    molecule-1   COMPOUND  PHENOTYPE   \n",
       "\n",
       "                                   shortest dep path  \\\n",
       "0  ['nmod', 'effect', 'nmod', 'interest', 'nmod',...   \n",
       "1                      ['nsubj', 'improved', 'dobj']   \n",
       "2  ['nsubj', 'improved', 'dep', 'effects', 'acl:r...   \n",
       "3  ['nmod', 'Normalization', 'nsubj', 'finding', ...   \n",
       "4  ['nmod', 'effects', 'dobj', 'justifies', 'acl:...   \n",
       "\n",
       "                                            sentence  sentence id      pmid  \n",
       "0  As a result of recent interest in the carcinog...            0      None  \n",
       "1  Vildagliptin markedly improved the motor perfo...            1  25752913  \n",
       "2  Vildagliptin markedly improved the motor perfo...            1  25752913  \n",
       "3  Normalization of receptor for advanced glycate...            2  25752913  \n",
       "4  Normalization of receptor for advanced glycate...            2  25752913  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(data_dict)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3aeaf1c-bab7-4595-baa0-40c66511739f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61727dd7-f16b-48b7-9420-16ed2868153e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64f1a814-33f3-410c-a1f4-9b9597bfcc1e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Run EBC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef60b03-64e6-43a5-b6fb-f28b36c518d0",
   "metadata": {},
   "source": [
    "## Analyse results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f343fa06-3007-4e37-84af-f245f5d3b44b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
